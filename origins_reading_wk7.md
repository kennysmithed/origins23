---
title: Week 7 pre-lecture reading
description: The evolution of social cognition
---

*As usual, read this blog, do the reading, and then take the quiz on Top Hat to test your understanding.*

This week we want you to read [Woensdregt & Smith (2017)](papers/woensdregt_2017_pragmatics.pdf). The first author, [Marieke Woensdregt](https://marieke-woensdregt.github.io), is a postdoc at the MPI in Nijmegen, but did her PhD with me back in the day, working on computational models of language the co-evolution of theory of mind.

## About the reading

The aim of the article is to provide a brief review of some of the key evolutionary questions concerning pragmatics, the ability to make and exploit inferences about others’ minds during communication. There is some debate about exactly how sophisticated a mindreader you need to be for this kind of communication. As reviewed in the reading, some authors (notably, [Dan Sperber](http://www.dan.sperber.fr)) argue that it requires the ability to deal with complex embedded representations of the beliefs that others have about your beliefs and so on; [Richard Moore](https://warwick.ac.uk/fac/soc/philosophy/people/summaries/moore/) argues that far more basic cognitive capacities might be required. Either way, human capacities for representing and reasoning about mental states in others seem to far outstrip the capacities of our closest relatives, the other great apes, who are capable of representing what other individuals know, but possibly not that other individuals can have false beliefs about the world. The article ends by reviewing possible explanations for the evolution of sophisticated theory of mind in humans, including explanations appealing to biological evolution (perhaps our uniquely complex social/technological niche generated selection for enhanced mindreading capacities) or cultural evolution (including the possibility that language and theory of mind co-evolved).

## An additional note on subdoxastic states

[This is some clarification provided by Marieke on the rather technical issue of subdoxastic states that are mentioned briefly in the paper.]

The idea behind discussing ‘subdoxastic states’ is that many people refer to so-called ‘belief-like states’ when describing the ToM abilities of infants or great apes, without really defining what those are. This resulted in people talking past each other when discussing whether or not infants ‘have a theory of mind’, and that issue was addressed by Hannes Rakoczy in this 2012 paper [see the reading for full reference]. He decided to use terminology from philosophy of mind, where ideas about different kinds of representations have already been formalised, so that is where the term ‘subdoxastic state’ comes from.

Basically the idea is that subdoxastic states are mental states that fall short of being a ‘proper belief’ (a.k.a. ‘propositional attitude’). For something to be a proper belief it has to be i) accessible to consciousness; ii) integratable with the rest of the information in our mind, so that we can make inferences with it and reason with it; iii) their content has to be properly ‘conceptual’, which means that we have to be able to describe/define the content of the belief.

Now when we’re describing the ToM abilities of infants or great apes, subdoxastic states can play a role on two different levels. Firstly, the mental state representation itself can be subdoxastic, which would for instance have the consequence that the individual shows implicit signs of awareness of the mental state of another agent (e.g. eye-gaze) but cannot explicitly act on that representation (because (i) it is not available to consciousness and (ii) cannot be integrated with the rest of the individual’s knowledge).

Secondly, it can be that the mental state representation contains a mental state that falls short of being a proper belief. So the infant/ape might be able to represent ‘Sally desires that the marble is in the box’ or ‘Sally hopes that the marble is in the box’, without being able to represent ‘Sally believes that the marble is in the box’. These three different representations could lead to the same behaviour in terms of eye-gaze, but the third requires a full-blown concept of belief, whereas the first two do not. And a full-blown concept of belief is harder to acquire because it requires an understanding that other agents’ representations of the world are representations, which are independent from the real state of the world (i.e. are subjective and can be true or false). Such a subdoxastic state inside the representation of another agent’s mental state is what is often referred to as a ‘belief-like state’ (see e.g. [Apperly & Butterfill, 2009](https://pubmed.ncbi.nlm.nih.gov/19839692/)).

## Reading

[Woensdregt, M., & Smith, K. (2017). Pragmatics and language evolution. In M. Aronoff et al. (Eds.), <i>Oxford Research Encyclopedia of Linguistics</i>. Oxford: Oxford University Press.](papers/woensdregt_2017_pragmatics.pdf))

## Additional references

Apperly, I. A., & Butterfill, S. A. (2009). Do humans have two systems to track beliefs and belief-like states? <i>Psychological Review, 116</i>, 953-970.

## Re-use


All aspects of this work are licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).
